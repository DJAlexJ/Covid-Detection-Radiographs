import albumentations as A
from albumentations.pytorch.transforms import ToTensorV2
from config import DefaultConfig


def get_train_transforms():
    return A.Compose(
        [
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.OneOf(
                [
                    A.HueSaturationValue(
                        hue_shift_limit=0.2,
                        sat_shift_limit=0.2,
                        val_shift_limit=0.2,
                        p=0.3,
                    ),
                    A.RandomBrightnessContrast(
                        brightness_limit=0.2, contrast_limit=0.2, p=0.3
                    ),
                ],
                p=0.2,
            ),
            A.Resize(
                height=DefaultConfig.img_size, width=DefaultConfig.img_size, p=1.0
            ),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                max_pixel_value=255.0,
                p=1.0,
            ),
            ToTensorV2(p=1.0),
        ],
        p=1.0,
        bbox_params={"format": "pascal_voc", "label_fields": ["labels"]},
    )


def get_valid_transforms():
    return A.Compose(
        [
            A.Resize(
                height=DefaultConfig.img_size, width=DefaultConfig.img_size, p=1.0
            ),
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                max_pixel_value=255.0,
                p=1.0,
            ),
            ToTensorV2(p=1.0),
        ],
        p=1.0,
        bbox_params={"format": "pascal_voc", "label_fields": ["labels"]},
    )
